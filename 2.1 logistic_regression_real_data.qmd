---
title: "Centered algorithms using real data - Logistic regression"
author: "Juan Li"
date: 2025-11-24
format: 
  html:
    toc: true
    html-math-method: katex
    css: styles.css
editor: visual
---

```{r}
#| warning: false
#| message: false
#| output: false

library(dplyr) # Data manipulation
library(tidyr) # Tidy messy data
library(ggplot2) # Data visualization
library(ggpubr) # ggarrange
library(patchwork)
library(fastDummies) # make dummy variables
library(rms)
library(pROC)

source("R/util.R") 
# functions in "util.R"
# get_rcs: implement the formula of rcs components
# step_dummy: dummy variables
# step_rcs: rcs
# step_interaction: interaction terms
# step_center: centering
# get_mean: get mean values from the original dataset
# root.search: Root searching, not in use in this .qmd file

source("R/calibration.R") # for calibration plots
```

# Dataset: Heart Disease Dataset

We will use the [Heart Disease Dataset](https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset) dataset for the examples.

About this dataset, see this \[notebook\] (https://www.kaggle.com/code/tentotheminus9/what-causes-heart-disease-explaining-the-model)

1.  `age`: continuous. The person's age in years

2.  `sex`: categorical. The person's sex (1 = male, 0 = female)

3.  `cp`: categorical. The chest pain experienced (0: typical angina, 1: atypical angina, 2: non-anginal pain, 3: asymptomatic)

4.  `trestbps`: continuous. The person's resting blood pressure (in mm Hg on admission to the hospital)

5.  `chol`: continuous. The person's serum cholestoral in mg/dl

6.  `fbs`: categorical. The person's fasting blood sugar (\> 120 mg/dl, 1 = true; 0 = false)

7.  `restecg`: categorical. Resting electrocardiographic measurement (0 = normal, 1 = having ST-T wave abnormality, 2 = showing probable or definite left ventricular hypertrophy by Estes' criteria)

8.  `thalach`: continuous. The person's maximum heart rate achieved

9.  `exang`: categorical. Exercise induced angina (0 = no; 1 = yes)

10. `oldpeak`: continuous. ST depression induced by exercise relative to rest ('ST' relates to positions on the ECG plot. See more here)

11. `slope`: categorical. the slope of the peak exercise ST segment (0: upsloping, 1: flat, 2: downsloping)

12. `ca`: The number of major vessels (0-3) colored by flourosopy

13. `thal`: categorical. A blood disorder called thalassemia (1 = normal; 2 = fixed defect; 3 = reversable defect)

14. `target`: Heart disease (0 = no, 1 = yes)

```{r}
data <- read.csv("data/heart.csv", stringsAsFactors = TRUE)
dim(data) # there is no missing data in this dataset

data <- data %>% mutate(thal = ifelse(thal == 0, 1, thal)) # 7 cases that thal == 0, collapse levels to 1`
data_num <- data

# categorical variables
vars_cat <- c("sex", "cp", "fbs", "restecg", "exang", "slope", "thal")
data[vars_cat] <- lapply(data[vars_cat], factor) 

summary(data)

## Barplots for all predictors

df_long <- pivot_longer(
  data_num,
  -c(target),
  names_to = "variable",
  values_to = "value"
)

ggplot(df_long, aes(value, fill = factor(target))) +
  geom_histogram() +
  facet_wrap(~variable, scales = "free") +
  theme_minimal()
```

## correlation

```{r}
#| fig.width: 12
#| fig.height: 12

library(corrplot)

# -------- dummy variables --------
data_cor <- step_dummy(data, vars_cat)

M <- cor(data_cor %>% select(-all_of(vars_cat)))
corrplot(M, method = 'number') 

table(data %>% select(fbs, target))
prop.table(table(data %>% select(fbs, target)), 1)
```

## Data sampling

From above figures, it appears that `fbs` doesn't have a strong correlation with `target`. In order to exaggrate the difference from `train` and `test` sets, I'll use the `fbs == 0` data as the `train` dataset, and the `fbs == 1` data as the `test` dataset.

```{r}
train <- data %>% filter(fbs == 0) %>% select(-fbs)
test <- data %>% filter(fbs == 1) %>% select(-fbs)
```

```{r}
library(gtsummary)

data %>% 
  mutate(type = ifelse(fbs == 0, "train", "test")) %>% 
  tbl_summary(by = "type") %>% 
  modify_header(label = "**Variable**") %>% # update the column header
  modify_caption("Table 1. Summary of the two datasets") %>%
  bold_labels() %>% 
  as_flex_table()
```

# Original and centered models using the `train` dataset

There is no easy data visualization like in `1.4 linear_regression_real_data.qmd` to suggest the nonlinear and interaction terms. For the purpose of this example, I'll just use below model.

```{r}
# The original model
fit.o <- glm(target ~ 
  cp + trestbps + chol + restecg + thalach + exang + ca + thal +
  sex * rcs(age,4) + slope * oldpeak, data = train, family = "binomial")
```

```{r}
# Get the centered variables and terms
# -------- dummy variables --------
vars_cat <- c("sex", "cp", "restecg", "exang", "slope", "thal")
train <- step_dummy(train, vars_cat)

# -------- rcs --------
# age
rcs.fit <- rcs(train$age, 4)
age_knots_train <- attributes(rcs.fit)$parms # knot locations
# unpack rcs
vars_rcs <- c("age")
knots_list <- list(age_knots_train)
knots_list <- setNames(knots_list, vars_rcs)
train <- step_rcs(train, vars_rcs, knots_list)

# -------- interaction terms --------
interaction_list <- list(
  c("sex", "age"),
  c("slope", "oldpeak")
)
train <- step_interaction(train, interaction_list)

# -------- centering --------
vars_mean <- names(train)
# get mean values
means_train <- get_mean(train, vars_mean)
# centering vars in the train dataset
vars_center <- names(means_train)
train <- step_center(train, vars_center, means_train)
```

```{r}
# The centered model on the trin dataset
fit.c <- glm(target ~ 
  cp_1_C + cp_2_C + cp_3_C + trestbps_C + chol_C + restecg_1_C + restecg_2_C + thalach_C + exang_1_C + ca_C + thal_2_C + thal_3_C +
  sex_1_C + age_rcs_1_C + age_rcs_2_C + age_rcs_3_C + slope_1_C + slope_2_C + oldpeak_C +
  sex_1_by_age_rcs_1_C + sex_1_by_age_rcs_2_C + sex_1_by_age_rcs_3_C + slope_1_by_oldpeak_C + slope_2_by_oldpeak_C, data = train, family = "binomial")

cbind(coef(fit.o), coef(fit.c))

# outcome mean
y_mean <- mean(train$target)
y_mean_logit <- log(y_mean/(1-y_mean)) # this is equal to log(n_target_1/n_target_0)
paste0("Mean outcome: ", y_mean)
paste0("Logit (log-odds) of the mean outcome: ", y_mean_logit)

# global offset
offset <- coef(fit.c)[1] - y_mean_logit
paste0("Global offset: ", offset)
```

```{r}
# prediction
train$pred.o <- predict(fit.o, newdata = train, type = "response")
train$pred.c <- predict(fit.c, newdata = train, type = "response")

head(train %>% select(contains("pred")))
```

```{r}
# AUC
roc.o <- roc(train$target, train$pred.o, levels=c(0, 1), na.rm=TRUE, ci=TRUE) 
paste0("AUC of the original model within TRAIN dataset: ", roc.o$auc)
roc.c <- roc(train$target, train$pred.c, levels=c(0, 1), na.rm=TRUE, ci=TRUE) 
paste0("AUC of the centered model within TRAIN dataset: ", roc.c$auc)
```

# Apply the models on the `test` dataset

```{r}
# Preprocess the `test` dataset

# -------- dummy variables --------
test <- step_dummy(test, vars_cat)

# -------- rcs --------
# IMPORTANT: using the knot locations in the `train` dataset
test <- step_rcs(test, vars_rcs, knots_list)

# -------- interaction terms --------
test <- step_interaction(test, interaction_list)

# -------- centering --------
# 1. centering using the mean values in the `train` dataset
# This is for transporting the centered algorithm
test_means_train <- step_center(test, vars_center, means_train)

# 2. centering using the mean values in the `test` dataset
# This is for recalibration
# get mean values
means_test <- get_mean(test, vars_mean)
# centering vars in the test dataset
test_means_test <- step_center(test, vars_center, means_test)
```

## Re-calibrate/Update the model in the test dataset

Based on `doc/Centered algorithm summary_2025-11-17.docx`, re-calibration can be done by update the outcome mean, but keep using the variable means in the **train** dataset.

```{r}
# outcome mean in the test dataset
y_mean_test <- mean(test$target)
y_mean_logit_test <- log(y_mean_test/(1-y_mean_test)) # this is equal to log(n_target_1/n_target_0)
paste0("Mean outcome: ", y_mean_test)
paste0("Logit (log-odds) of the mean outcome: ", y_mean_logit_test)

# update the model
fit.c.2 <- fit.c
fit.c.2$coefficients[1] <- y_mean_logit_test + offset
```

```{r}
# The original model on the test dataset
test_means_train$pred.logit.o <- predict(fit.o, newdata = test_means_train)

# The centered model on the test dataset
test_means_train$pred.logit.c <- predict(fit.c, newdata = test_means_train)

# The re-calibrated model on the test dataset
test_means_train$pred.logit.c.2 <- predict(fit.c.2, newdata = test_means_train)

# check
paste0("Difference between log[E(Y=1)] in test and log[E(Y=1)] in train: ", y_mean_logit_test-y_mean_logit)
head(cbind(
  test_means_train$pred.logit.o,
  test_means_train$pred.logit.c,
  test_means_train$pred.logit.c.2,
  test_means_train$pred.logit.c.2 - test_means_train$pred.logit.c
))
```

```{r}
# The original model on the test dataset
test_means_train$pred.o <- predict(fit.o, newdata = test_means_train, type = "response")

# The centered model on the test dataset
test_means_train$pred.c <- predict(fit.c, newdata = test_means_train, type = "response")

# The re-calibrated model on the test dataset
test_means_train$pred.c.2 <- predict(fit.c.2, newdata = test_means_train, type = "response")

# check
head(cbind(
  test_means_train$pred.o,
  test_means_train$pred.c,
  test_means_train$pred.c.2
))
```

NOTE: since re-calibration is just shifting predicted probabilities horizontally, it will NOT affect discrimination, i.e., AUC.

```{r}
# AUC
roc.o <- roc(test$target, test_means_train$pred.o, levels=c(0, 1), na.rm=TRUE, ci=TRUE) 
paste0("AUC of the original model within TEST dataset: ", roc.o$auc)
roc.c <- roc(test$target, test_means_train$pred.o, levels=c(0, 1), na.rm=TRUE, ci=TRUE) 
paste0("AUC of the centered model within TEST dataset: ", roc.c$auc)

roc.c.2 <- roc(test$target, test_means_train$pred.c.2, levels=c(0, 1), na.rm=TRUE, ci=TRUE) 
paste0("AUC of the recalibrated model within TEST dataset: ", roc.c.2$auc)
```

## Some calibration plots on the test dataset

```{r}
res <- calibration(test_means_train$pred.o, test_means_train$target, package = "rms")
res
```

```{r}
res <- calibration(test_means_train$pred.c, test_means_train$target, package = "rms")
res
```

```{r}
res <- calibration(test_means_train$pred.c.2, test_means_test$target, package = "rms")
res
```

```{r}

```
