---
title: "Centered algorithms - Logistic regression"
author: "Juan Li"
date: 2025-09-23
format: 
  html:
    toc: true
    html-math-method: katex
    css: styles.css
editor: visual
---

```{r}
#| warning: false
#| message: false
#| output: false

library(dplyr) # Data manipulation
library(tidyr) # Tidy messy data
library(ggplot2) # Data visualization
library(ggpubr) # ggarrange
library(patchwork)
library(fastDummies) # make dummy variables
library(rms)
library(pROC)

source("R/util.R") 
# functions in "util.R"
# get_rcs: implement the formula of rcs components
# step_dummy: dummy variables
# step_rcs: rcs
# step_interaction: interaction terms
# step_center: centering
# get_mean: get mean values from the original dataset
# get_logLik: a function to manually calculate log likehood when some of the coefficients are manually changed
# root.search: Root searching, not in use in this .qmd file

source("R/calibration.R") # for calibration plots
```

In this notebook, we will explain the issues of centered algorithm in logistic regression and explore the potential work-around. We will start with univariate analysis to get the math right. Then in "2.2 logistic_regression_real_data.qmd", we will put everything together.

# Dataset: Heart Disease Dataset

We will use the [Heart Disease Dataset](https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset) dataset for the examples.

About this dataset, see this \[notebook\] (https://www.kaggle.com/code/tentotheminus9/what-causes-heart-disease-explaining-the-model)

1.  `age`: continuous. The person's age in years

2.  `sex`: categorical. The person's sex (1 = male, 0 = female)

3.  `cp`: categorical. The chest pain experienced (0: typical angina, 1: atypical angina, 2: non-anginal pain, 3: asymptomatic)

4.  `trestbps`: continuous. The person's resting blood pressure (in mm Hg on admission to the hospital)

5.  `chol`: continuous. The person's serum cholestoral in mg/dl

6.  `fbs`: categorical. The person's fasting blood sugar (\> 120 mg/dl, 1 = true; 0 = false)

7.  `restecg`: categorical. Resting electrocardiographic measurement (0 = normal, 1 = having ST-T wave abnormality, 2 = showing probable or definite left ventricular hypertrophy by Estes' criteria)

8.  `thalach`: continuous. The person's maximum heart rate achieved

9.  `exang`: categorical. Exercise induced angina (0 = no; 1 = yes)

10. `oldpeak`: continuous. ST depression induced by exercise relative to rest ('ST' relates to positions on the ECG plot. See more here)

11. `slope`: categorical. the slope of the peak exercise ST segment (0: upsloping, 1: flat, 2: downsloping)

12. `ca`: The number of major vessels (0-3) colored by flourosopy

13. `thal`: categorical. A blood disorder called thalassemia (1 = normal; 2 = fixed defect; 3 = reversable defect)

14. `target`: Heart disease (0 = no, 1 = yes)

```{r}
data <- read.csv("data/heart.csv", stringsAsFactors = TRUE)
dim(data) # there is no missing data in this dataset

data <- data %>% mutate(thal = ifelse(thal == 0, 1, thal)) # 7 cases that thal == 0, collapse levels to 1`
data_num <- data

# categorical variables
vars_cat <- c("sex", "cp", "fbs", "restecg", "exang", "slope", "thal")
data[vars_cat] <- lapply(data[vars_cat], factor) 

summary(data)
```

# Logistic regression

For resources, see [here](https://bookdown.org/brianmachut/uofm_analytics_r_hw_sol_2/logreg.html) and [hear](https://arunaddagatla.medium.com/maximum-likelihood-estimation-in-logistic-regression-f86ff1627b67).

Formula of logistic regression: for a regression model with $p$ predictors,

$p(X) = \frac{e^{\beta_0 + \beta_1X_1 + ... + \beta_pX_p}}{1+e^{\beta_0 + \beta_1X_1 + ... + \beta_pX_p}}$

The formula can also be written as:

$\frac{p}{1-p} = e^{\beta_0 + \beta_1X_1 + ... + \beta_pX_p}$

Also as:

$ln(\frac{p}{1-p}) = \beta_0 + \beta_1X_1 + ... + \beta_pX_p$

Then if the centering works as in linear regression (see quatro files 1.1 to 1.4), we would expect that, after centering, the new intercept

$\beta_0^{centered} = ln(\frac{\overline{p}}{1-\overline{p}})$,

where $\overline{p}$ is the outcome mean/prevalence of the case.

**The issue is that, with the simple centering, the adjusted intercept is not identical to the logit (log-odds) of the outcome mean.** That is because logistic regression models are fitted using **Maximum Likelihood Estimation (MLE)** instead of least squares as in linear regression.

# One categorical/dichotomous variable: sex

```{r}
df <- data %>% select(sex, target)

# -------- dummy variables --------
vars_cat <- c("sex")
df <- step_dummy(df, vars_cat)

# -------- centering --------
vars_mean <- names(df)
# get mean values
means <- get_mean(df, vars_mean)
# centering vars
vars_center <- names(means)
df <- step_center(df, vars_center, means)

head(df)

# fit the original model
fit.o <- glm(target ~ sex, data = df, family = "binomial")

# fit the centered model
fit.c <- glm(target ~ sex_1_C, data = df, family = "binomial")

# outcome mean
y_mean <- mean(df$target)
y_mean_logit <- log(y_mean/(1-y_mean))
paste0("Mean outcome: ", y_mean)
paste0("Logit (log-odds) of the mean outcome: ", log(y_mean/(1-y_mean)))

# model coefficients
cbind(coef(fit.o), coef(fit.c))
```

One simple work-around is to manually set the new intercept after centering using the logit of outcome mean. Below results confirm that this manual shifting only has a neglegible effect on the log likelihood, and no effect on AUC (because a constant shift doesn't affect the ranking).

```{r}
# centered model, with manually setting the intercept to the mean outcome
fit.c.2 <- fit.c
fit.c.2$coefficients[1] <- y_mean_logit

# model coefficients
cbind(coef(fit.o), coef(fit.c), coef(fit.c.2))

# prediction: note `fit.o` and `fit.c` have the same predicted value, while `fit.c.2` has a different one
df$pred.o <- predict(fit.o, newdata = df, type = "response")
df$pred.c <- predict(fit.c, newdata = df, type = "response")
df$pred.c.2 <- predict(fit.c.2, newdata = df, type = "response")

head(df %>% select(contains("pred")))
```

The log likelihood value can be manually calculated using function `get_logLik`, see `R/util.R`.

```{r}
# log likelihood
# --- original model ---
paste0("Log likelihood of the original model, by extracting: ", logLik(fit.o))
paste0("Log likelihood of the original model, by calculating: ", get_logLik(df$target, df$pred.o, coef(fit.o)))
# --- centered model ---
paste0("Log likelihood of the centered model, by extracting: ", logLik(fit.c))
paste0("Log likelihood of the centered model, by calculating: ", get_logLik(df$target, df$pred.c, coef(fit.c)))
# --- centered model with adjusted intercept ---
paste0("Log likelihood of the centered model with adjusted intercept: ", get_logLik(df$target, df$pred.c.2, coef(fit.c.2)))
```

```{r}
# AUC
roc.o <- roc(df$target, df$pred.o, levels=c(0, 1), na.rm=TRUE, ci=TRUE) 
paste0("AUC of the original model: ", roc.o$auc)
roc.c <- roc(df$target, df$pred.c, levels=c(0, 1), na.rm=TRUE, ci=TRUE) 
paste0("AUC of the centered model: ", roc.c$auc)
roc.c.2 <- roc(df$target, df$pred.c.2, levels=c(0, 1), na.rm=TRUE, ci=TRUE) 
paste0("AUC of the centered model with a different intercept: ", roc.c.2$auc)
```

# One continuous variable: age

With one continuous variable, logit of the outcome mean and intercept of the centered algorithm are very close. Manually change the intercept will have even smaller effect on log likelihood and AUC.

```{r}
df <- data %>% select(age, target)

# -------- centering --------
vars_mean <- names(df)
# get mean values
means <- get_mean(df, vars_mean)
# centering vars
vars_center <- names(means)
df <- step_center(df, vars_center, means)

head(df)

# fit the original model
fit.o <- glm(target ~ age, data = df, family = "binomial")

# fit the centered model
fit.c <- glm(target ~ age_C, data = df, family = "binomial")

# outcome mean
y_mean <- mean(df$target)
y_mean_logit <- log(y_mean/(1-y_mean))
paste0("Mean outcome: ", y_mean)
paste0("Logit (log-odds) of the mean outcome: ", y_mean_logit)

# model coefficients
cbind(coef(fit.o), coef(fit.c))
```

```{r}
# centered model, with manually setting the intercept to the mean outcome
fit.c.2 <- fit.c
fit.c.2$coefficients[1] <- y_mean_logit

# model coefficients
cbind(coef(fit.o), coef(fit.c), coef(fit.c.2))

# prediction: note `fit.o` and `fit.c` have the same predicted value, while `fit.c.2` has a different one
df$pred.o <- predict(fit.o, newdata = df, type = "response")
df$pred.c <- predict(fit.c, newdata = df, type = "response")
df$pred.c.2 <- predict(fit.c.2, newdata = df, type = "response")

head(df %>% select(contains("pred")))
```

```{r}
# log likelihood
# --- original model ---
paste0("Log likelihood of the original model, by extracting: ", logLik(fit.o))
paste0("Log likelihood of the original model, by calculating: ", get_logLik(df$target, df$pred.o, coef(fit.o)))
# --- centered model ---
paste0("Log likelihood of the centered model, by extracting: ", logLik(fit.c))
paste0("Log likelihood of the centered model, by calculating: ", get_logLik(df$target, df$pred.c, coef(fit.c)))
# --- centered model with adjusted intercept ---
paste0("Log likelihood of the centered model with adjusted intercept: ", get_logLik(df$target, df$pred.c.2, coef(fit.c.2)))
```

```{r}
# AUC
roc.o <- roc(df$target, df$pred.o, levels=c(0, 1), na.rm=TRUE, ci=TRUE) 
paste0("AUC of the original model: ", roc.o$auc)
roc.c <- roc(df$target, df$pred.c, levels=c(0, 1), na.rm=TRUE, ci=TRUE) 
paste0("AUC of the centered model: ", roc.c$auc)
roc.c.2 <- roc(df$target, df$pred.c.2, levels=c(0, 1), na.rm=TRUE, ci=TRUE) 
paste0("AUC of the centered model with a different intercept: ", roc.c.2$auc)
```

## Some calibration plots on the test dataset

```{r}
# ---------- Overall calibration ----------
# The original model 
res <- calibration(df$pred.o, df$target, marginPlt = TRUE)
res

# The centered model 
res <- calibration(df$pred.c, df$target, marginPlt = TRUE)
res

# The centered model, with manually setting the intercept to the mean outcome
res <- calibration(df$pred.c.2, df$target, marginPlt = TRUE)
res
```

```{r}

```